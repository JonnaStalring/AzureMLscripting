{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from tensorflow import keras\n",
    "\n",
    "# Scikit-optimizer\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "#from skopt.plots import plot_convergence\n",
    "#from skopt.plots import plot_objective, plot_evaluations\n",
    "#from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "best_accuracy = 0.0\n",
    "path_best_model_h5 = 'best_model_keras.h5'\n",
    "path_best_model_json = 'best_model_keras.json'\n",
    "modelpath = 'best_model_keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_name(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./19_logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(learning_rate,\n",
    "                       num_dense_layers,\n",
    "                       num_dense_nodes,\n",
    "                       activation)\n",
    "\n",
    "    return log_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyPart(data):\n",
    "    Xdata = data.iloc[:,0:177]\n",
    "    Ydata = []\n",
    "    for elem in data.iloc[:,177]:\n",
    "        if elem == \"Low\":\n",
    "            Ydata.append(0)\n",
    "        elif elem == \"High\":\n",
    "            Ydata.append(1)\n",
    "    Ydata = np.array(Ydata)\n",
    "    return Xdata, Ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name))\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, path_best_model_h5, path_best_model_json):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(path_best_model_json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(path_best_model_h5)\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(path_best_model_h5, path_best_model_json):\n",
    "    # load json and create model\n",
    "    json_file = open(path_best_model_json, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path_best_model_h5)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters to optimize\n",
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'], name='activation')\n",
    "dimensions = [dim_learning_rate, dim_num_dense_layers, dim_num_dense_nodes, dim_activation]\n",
    "default_parameters = [1e-5, 1, 16, 'relu'] # Same order as dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers,\n",
    "            num_dense_nodes, activation):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation)\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
    "                           num_dense_nodes, activation)\n",
    "\n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        batch_size=32,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "    \n",
    "    # Stop training dependent on validation accuracy - JGW\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=20)\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=ncXtrain.values,\n",
    "                        y=Ytrain,\n",
    "                        epochs=3,\n",
    "                        batch_size=128,\n",
    "                        validation_split = 0.2,\n",
    "                        callbacks=[callback_log, early_stop])\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "        # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        #saveModel(model, path_best_model_h5, path_best_model_json)\n",
    "        tf.keras.models.save_model(model, modelpath, overwrite=True, include_optimizer=True)\n",
    "\n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "\n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rdk.fr_C_O_noCOO', 'rdk.Chi4v', 'rdk.fr_Ar_COO', 'rdk.fr_SH',\n",
      "       'rdk.Chi4n', 'rdk.SMR_VSA10', 'rdk.fr_para_hydroxylation',\n",
      "       'rdk.fr_barbitur', 'rdk.fr_halogen', 'rdk.fr_dihydropyridine',\n",
      "       ...\n",
      "       'rdk.PEOE_VSA9', 'rdk.fr_aldehyde', 'rdk.fr_pyridine',\n",
      "       'rdk.fr_tetrazole', 'rdk.RingCount', 'rdk.fr_nitro_arom_nonortho',\n",
      "       'rdk.Chi0v', 'rdk.fr_ArN', 'rdk.NumRotatableBonds', 'c#ClappClass'],\n",
      "      dtype='object', length=178)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('HLMdesc.txt', sep=\"\\t\")\n",
    "data = data.drop(columns = ['Protocol Number', 'Experiment Start Time', 'Experiment Stop Time', 'Result Type Name', 'Result Operator', 'Result Number Rounded',\\\n",
    " 'Project NumName', 'Smiles', 'Leonumber', 'DResult Text', 'DResult Text_1'])\n",
    "data = data.drop(columns = ['Protocol Number_1', 'Experiment Start Time_1', 'Experiment Stop Time_1', 'Result Type Name_1', 'Result Operator_1', 'Result Number Rounded_1', 'Project NumName_1',\\\n",
    "       'Leonumber_1', 'origSmiles_1', 'ClappClass_1'])\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rdk.fr_C_O_noCOO', 'rdk.Chi4v', 'rdk.fr_Ar_COO', 'rdk.fr_SH',\n",
      "       'rdk.Chi4n', 'rdk.SMR_VSA10', 'rdk.fr_para_hydroxylation',\n",
      "       'rdk.fr_barbitur', 'rdk.fr_halogen', 'rdk.fr_dihydropyridine',\n",
      "       ...\n",
      "       'rdk.MolMR', 'rdk.PEOE_VSA9', 'rdk.fr_aldehyde', 'rdk.fr_pyridine',\n",
      "       'rdk.fr_tetrazole', 'rdk.RingCount', 'rdk.fr_nitro_arom_nonortho',\n",
      "       'rdk.Chi0v', 'rdk.fr_ArN', 'rdk.NumRotatableBonds'],\n",
      "      dtype='object', length=177)\n"
     ]
    }
   ],
   "source": [
    "# Seperate test set\n",
    "train = data.sample(frac=0.8,random_state=0)\n",
    "test = data.drop(train.index)\n",
    "#print(len(train))\n",
    "#print(len(test))\n",
    "Xtrain, Ytrain = xyPart(train)\n",
    "Xtest, Ytest = xyPart(test)\n",
    "print(Xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "data_stats = Xtrain.describe()\n",
    "data_stats = data_stats.transpose()\n",
    "def norm(x):\n",
    "  return (x - data_stats['mean']) / data_stats['std']\n",
    "nXtrain = norm(Xtrain)\n",
    "nXtest = norm(Xtest)\n",
    "#print(Xtrain.values[0])\n",
    "#print(nXtrain.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rm columns containing NA\n",
    "allCol = nXtrain.columns\n",
    "ncXtrain = nXtrain.dropna(axis='columns')\n",
    "col = ncXtrain.columns  # After removing NA cols\n",
    "delCol = []\n",
    "for c in allCol:\n",
    "    if c not in col:\n",
    "        delCol.append(c)\n",
    "ncXtest = nXtest.drop(delCol, axis=1)\n",
    "#print(nXtrain.values[0])\n",
    "#print(ncXtrain.values[0])\n",
    "#print(ncXtest.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 256\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 151us/step - loss: 0.6708 - acc: 0.4675 - val_loss: 0.6663 - val_acc: 0.5224\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 88us/step - loss: 0.6640 - acc: 0.5519 - val_loss: 0.6655 - val_acc: 0.6253\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 84us/step - loss: 0.6633 - acc: 0.5017 - val_loss: 0.6651 - val_acc: 0.5890\n",
      "\n",
      "Accuracy: 58.90%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.589029535512884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(x=[1e-4, 3, 256, 'relu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 155us/step - loss: 0.9299 - acc: 0.1681 - val_loss: 0.9192 - val_acc: 0.1654\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 59us/step - loss: 0.9236 - acc: 0.1722 - val_loss: 0.9133 - val_acc: 0.1688\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 81us/step - loss: 0.9177 - acc: 0.1741 - val_loss: 0.9075 - val_acc: 0.1722\n",
      "\n",
      "Accuracy: 17.22%\n",
      "\n",
      "learning rate: 5.3e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 386\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 233us/step - loss: 0.6823 - acc: 0.4876 - val_loss: 0.6650 - val_acc: 0.9907\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 117us/step - loss: 0.6621 - acc: 0.5259 - val_loss: 0.6635 - val_acc: 0.2118\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 116us/step - loss: 0.6616 - acc: 0.5365 - val_loss: 0.6634 - val_acc: 0.6354\n",
      "\n",
      "Accuracy: 63.54%\n",
      "\n",
      "learning rate: 1.8e-05\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 77\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 154us/step - loss: 0.6753 - acc: 0.9040 - val_loss: 0.6698 - val_acc: 0.8034\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 73us/step - loss: 0.6670 - acc: 0.6996 - val_loss: 0.6672 - val_acc: 0.6287\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 83us/step - loss: 0.6654 - acc: 0.5888 - val_loss: 0.6665 - val_acc: 0.5747\n",
      "\n",
      "Accuracy: 57.47%\n",
      "\n",
      "learning rate: 5.0e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 173\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 242us/step - loss: 0.7236 - acc: 0.5435 - val_loss: 0.6667 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 101us/step - loss: 0.6625 - acc: 0.4804 - val_loss: 0.6634 - val_acc: 0.8861\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 123us/step - loss: 0.6616 - acc: 0.4582 - val_loss: 0.6633 - val_acc: 0.3671\n",
      "\n",
      "Accuracy: 36.71%\n",
      "\n",
      "learning rate: 2.9e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 437\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 399us/step - loss: 0.6804 - acc: 0.4608 - val_loss: 0.6635 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 311us/step - loss: 0.6619 - acc: 0.5563 - val_loss: 0.6633 - val_acc: 0.9181\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 2s 331us/step - loss: 0.6616 - acc: 0.5508 - val_loss: 0.6633 - val_acc: 0.9924\n",
      "\n",
      "Accuracy: 99.24%\n",
      "\n",
      "learning rate: 2.8e-05\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 349\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 289us/step - loss: 0.6794 - acc: 0.4021 - val_loss: 0.6649 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 155us/step - loss: 0.6618 - acc: 0.3949 - val_loss: 0.6633 - val_acc: 0.5215\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 156us/step - loss: 0.6616 - acc: 0.5291 - val_loss: 0.6633 - val_acc: 0.4608\n",
      "\n",
      "Accuracy: 46.08%\n",
      "\n",
      "learning rate: 5.6e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 238\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 171us/step - loss: 0.6716 - acc: 0.5401 - val_loss: 0.6634 - val_acc: 8.4388e-04\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 100us/step - loss: 0.6617 - acc: 0.4580 - val_loss: 0.6633 - val_acc: 0.6414\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 120us/step - loss: 0.6616 - acc: 0.4127 - val_loss: 0.6633 - val_acc: 0.1527\n",
      "\n",
      "Accuracy: 15.27%\n",
      "\n",
      "learning rate: 3.0e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 384\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 362us/step - loss: 0.7965 - acc: 0.4329 - val_loss: 0.6667 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 301us/step - loss: 0.6631 - acc: 0.5401 - val_loss: 0.6636 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 303us/step - loss: 0.6616 - acc: 0.4865 - val_loss: 0.6633 - val_acc: 0.0000e+00\n",
      "\n",
      "Accuracy: 0.00%\n",
      "\n",
      "learning rate: 2.6e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 318\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 261us/step - loss: 0.6655 - acc: 0.4981 - val_loss: 0.6646 - val_acc: 0.4017\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 161us/step - loss: 0.6652 - acc: 0.5800 - val_loss: 0.6642 - val_acc: 0.7502\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 153us/step - loss: 0.6632 - acc: 0.4996 - val_loss: 0.6642 - val_acc: 0.2565\n",
      "\n",
      "Accuracy: 25.65%\n",
      "\n",
      "learning rate: 3.2e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 117\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 132us/step - loss: 0.6666 - acc: 0.4791 - val_loss: 0.6636 - val_acc: 0.9342\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - ETA: 0s - loss: 0.6657 - acc: 0.484 - 0s 78us/step - loss: 0.6617 - acc: 0.5000 - val_loss: 0.6633 - val_acc: 0.0751\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 73us/step - loss: 0.6616 - acc: 0.4473 - val_loss: 0.6633 - val_acc: 0.5215\n",
      "\n",
      "Accuracy: 52.15%\n",
      "\n",
      "learning rate: 8.5e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 31\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 0s 97us/step - loss: 0.6799 - acc: 0.5937 - val_loss: 0.6647 - val_acc: 0.3679\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 46us/step - loss: 0.6624 - acc: 0.6300 - val_loss: 0.6638 - val_acc: 0.5021\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 41us/step - loss: 0.6619 - acc: 0.5669 - val_loss: 0.6636 - val_acc: 0.5038\n",
      "\n",
      "Accuracy: 50.38%\n",
      "\n",
      "learning rate: 3.8e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 445\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 180us/step - loss: 0.6677 - acc: 0.4804 - val_loss: 0.6643 - val_acc: 0.9916\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 122us/step - loss: 0.6618 - acc: 0.4992 - val_loss: 0.6634 - val_acc: 0.1350\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 133us/step - loss: 0.6616 - acc: 0.4734 - val_loss: 0.6634 - val_acc: 0.4962\n",
      "\n",
      "Accuracy: 49.62%\n",
      "\n",
      "learning rate: 1.2e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 190\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 165us/step - loss: 0.7022 - acc: 0.5671 - val_loss: 0.6643 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 117us/step - loss: 0.6623 - acc: 0.4321 - val_loss: 0.6633 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 100us/step - loss: 0.6616 - acc: 0.5939 - val_loss: 0.6633 - val_acc: 0.0000e+00\n",
      "\n",
      "Accuracy: 0.00%\n",
      "\n",
      "learning rate: 1.9e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 476\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 518us/step - loss: 0.6642 - acc: 0.5143 - val_loss: 0.6635 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 2s 380us/step - loss: 0.6616 - acc: 0.4770 - val_loss: 0.6633 - val_acc: 0.0177\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 2s 355us/step - loss: 0.6616 - acc: 0.5302 - val_loss: 0.6633 - val_acc: 0.1409\n",
      "\n",
      "Accuracy: 14.09%\n",
      "\n",
      "learning rate: 1.3e-06\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 13\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 0s 91us/step - loss: 1.0042 - acc: 0.1916 - val_loss: 0.9724 - val_acc: 0.2017\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4740/4740 [==============================] - 0s 36us/step - loss: 1.0031 - acc: 0.1918 - val_loss: 0.9714 - val_acc: 0.2042\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 1.0020 - acc: 0.1922 - val_loss: 0.9704 - val_acc: 0.2042\n",
      "\n",
      "Accuracy: 20.42%\n",
      "\n",
      "learning rate: 1.1e-06\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 497\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 126us/step - loss: 0.7247 - acc: 0.7513 - val_loss: 0.7189 - val_acc: 0.7342\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 73us/step - loss: 0.7225 - acc: 0.7485 - val_loss: 0.7169 - val_acc: 0.7325\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 70us/step - loss: 0.7204 - acc: 0.7441 - val_loss: 0.7150 - val_acc: 0.7291\n",
      "\n",
      "Accuracy: 72.91%\n",
      "\n",
      "learning rate: 3.1e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 435\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 320us/step - loss: 0.6897 - acc: 0.5137 - val_loss: 0.6664 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 179us/step - loss: 0.6620 - acc: 0.5116 - val_loss: 0.6633 - val_acc: 0.6835\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 192us/step - loss: 0.6616 - acc: 0.4998 - val_loss: 0.6633 - val_acc: 0.5105\n",
      "\n",
      "Accuracy: 51.05%\n",
      "\n",
      "learning rate: 1.6e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 430\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 412us/step - loss: 0.7406 - acc: 0.5139 - val_loss: 0.6661 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 274us/step - loss: 0.6624 - acc: 0.4591 - val_loss: 0.6633 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 279us/step - loss: 0.6616 - acc: 0.4945 - val_loss: 0.6633 - val_acc: 1.0000\n",
      "\n",
      "Accuracy: 100.00%\n",
      "\n",
      "learning rate: 1.2e-06\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 414\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 346us/step - loss: 0.6773 - acc: 0.0173 - val_loss: 0.6742 - val_acc: 0.0371\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 269us/step - loss: 0.6707 - acc: 0.0776 - val_loss: 0.6696 - val_acc: 0.1080\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 272us/step - loss: 0.6670 - acc: 0.1669 - val_loss: 0.6672 - val_acc: 0.2127\n",
      "\n",
      "Accuracy: 21.27%\n",
      "\n",
      "learning rate: 4.9e-06\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 415\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 348us/step - loss: 0.6626 - acc: 0.3825 - val_loss: 0.6634 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 276us/step - loss: 0.6616 - acc: 0.3605 - val_loss: 0.6633 - val_acc: 0.4987\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 2s 327us/step - loss: 0.6616 - acc: 0.6719 - val_loss: 0.6633 - val_acc: 0.3148\n",
      "\n",
      "Accuracy: 31.48%\n",
      "\n",
      "learning rate: 1.0e-02\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 435\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 360us/step - loss: 7.5105 - acc: 0.0270 - val_loss: 7.7122 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 284us/step - loss: 7.6918 - acc: 0.0000e+00 - val_loss: 7.7122 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 283us/step - loss: 7.6918 - acc: 0.0000e+00 - val_loss: 7.7122 - val_acc: 0.0000e+00\n",
      "\n",
      "Accuracy: 0.00%\n",
      "\n",
      "learning rate: 7.4e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 432\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 420us/step - loss: 0.6732 - acc: 0.5139 - val_loss: 0.6638 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 286us/step - loss: 0.6618 - acc: 0.4340 - val_loss: 0.6634 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 276us/step - loss: 0.6616 - acc: 0.5188 - val_loss: 0.6633 - val_acc: 1.0000\n",
      "\n",
      "Accuracy: 100.00%\n",
      "\n",
      "learning rate: 1.1e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 427\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 346us/step - loss: 0.6744 - acc: 0.5006 - val_loss: 0.6634 - val_acc: 0.3021\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 270us/step - loss: 0.6617 - acc: 0.5192 - val_loss: 0.6633 - val_acc: 0.7578\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 278us/step - loss: 0.6616 - acc: 0.5774 - val_loss: 0.6634 - val_acc: 0.9882\n",
      "\n",
      "Accuracy: 98.82%\n",
      "\n",
      "learning rate: 1.1e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 434\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 363us/step - loss: 0.6754 - acc: 0.4350 - val_loss: 0.6634 - val_acc: 0.9890\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 282us/step - loss: 0.6616 - acc: 0.5224 - val_loss: 0.6633 - val_acc: 0.6135\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 283us/step - loss: 0.6616 - acc: 0.4987 - val_loss: 0.6633 - val_acc: 0.4397\n",
      "\n",
      "Accuracy: 43.97%\n",
      "\n",
      "learning rate: 8.4e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 428\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 345us/step - loss: 0.6915 - acc: 0.4861 - val_loss: 0.6638 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 2s 340us/step - loss: 0.6619 - acc: 0.5764 - val_loss: 0.6633 - val_acc: 0.9089 loss: 0.6583 - acc: \n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 275us/step - loss: 0.6616 - acc: 0.5038 - val_loss: 0.6633 - val_acc: 0.0954\n",
      "\n",
      "Accuracy: 9.54%\n",
      "\n",
      "learning rate: 1.4e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 426\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 348us/step - loss: 0.6715 - acc: 0.5139 - val_loss: 0.6633 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 2s 357us/step - loss: 0.6618 - acc: 0.4386 - val_loss: 0.6633 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 292us/step - loss: 0.6616 - acc: 0.5525 - val_loss: 0.6633 - val_acc: 0.2928\n",
      "\n",
      "Accuracy: 29.28%\n",
      "\n",
      "learning rate: 1.3e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 416\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 183us/step - loss: 0.6996 - acc: 0.4869 - val_loss: 0.6655 - val_acc: 0.9156\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 154us/step - loss: 0.6629 - acc: 0.5538 - val_loss: 0.6637 - val_acc: 0.0338\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 125us/step - loss: 0.6617 - acc: 0.4553 - val_loss: 0.6633 - val_acc: 0.6700\n",
      "\n",
      "Accuracy: 67.00%\n",
      "\n",
      "learning rate: 1.5e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 417\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 365us/step - loss: 0.6836 - acc: 0.4243 - val_loss: 0.6633 - val_acc: 0.3806\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 279us/step - loss: 0.6616 - acc: 0.4791 - val_loss: 0.6633 - val_acc: 0.7561\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 286us/step - loss: 0.6616 - acc: 0.5200 - val_loss: 0.6633 - val_acc: 0.3924\n",
      "\n",
      "Accuracy: 39.24%\n",
      "\n",
      "learning rate: 1.4e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 448\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 170us/step - loss: 0.7298 - acc: 0.4753 - val_loss: 0.6814 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 146us/step - loss: 0.6649 - acc: 0.5228 - val_loss: 0.6634 - val_acc: 0.6582\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 150us/step - loss: 0.6617 - acc: 0.5152 - val_loss: 0.6633 - val_acc: 0.2751\n",
      "\n",
      "Accuracy: 27.51%\n",
      "\n",
      "learning rate: 1.7e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 431\n",
      "activation: sigmoid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 235us/step - loss: 0.7066 - acc: 0.5329 - val_loss: 0.6635 - val_acc: 0.9519\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 162us/step - loss: 0.6619 - acc: 0.4791 - val_loss: 0.6633 - val_acc: 0.7570\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 169us/step - loss: 0.6616 - acc: 0.5603 - val_loss: 0.6633 - val_acc: 0.6329\n",
      "\n",
      "Accuracy: 63.29%\n",
      "\n",
      "learning rate: 9.1e-05\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 443\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 310us/step - loss: 0.6673 - acc: 0.5154 - val_loss: 0.6644 - val_acc: 0.5215\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 222us/step - loss: 0.6628 - acc: 0.5401 - val_loss: 0.6640 - val_acc: 0.4776\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 241us/step - loss: 0.6629 - acc: 0.5116 - val_loss: 0.6639 - val_acc: 0.5114\n",
      "\n",
      "Accuracy: 51.14%\n",
      "\n",
      "learning rate: 1.4e-06\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 508\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 282us/step - loss: 0.6726 - acc: 0.0000e+00 - val_loss: 0.6690 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 236us/step - loss: 0.6646 - acc: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 237us/step - loss: 0.6621 - acc: 0.0021 - val_loss: 0.6635 - val_acc: 0.0169\n",
      "\n",
      "Accuracy: 1.69%\n",
      "\n",
      "learning rate: 2.6e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 424\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 172us/step - loss: 0.7517 - acc: 0.4808 - val_loss: 0.6674 - val_acc: 0.9722\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 123us/step - loss: 0.6631 - acc: 0.5281 - val_loss: 0.6636 - val_acc: 0.1283\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 118us/step - loss: 0.6617 - acc: 0.4707 - val_loss: 0.6634 - val_acc: 0.7873\n",
      "\n",
      "Accuracy: 78.73%\n",
      "\n",
      "learning rate: 5.2e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 419\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 352us/step - loss: 0.7328 - acc: 0.5255 - val_loss: 0.6633 - val_acc: 0.7831\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 258us/step - loss: 0.6616 - acc: 0.6137 - val_loss: 0.6633 - val_acc: 0.0093\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 266us/step - loss: 0.6616 - acc: 0.5207 - val_loss: 0.6633 - val_acc: 0.0987\n",
      "\n",
      "Accuracy: 9.87%\n",
      "\n",
      "learning rate: 1.5e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 428\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 230us/step - loss: 0.6901 - acc: 0.5175 - val_loss: 0.6659 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 179us/step - loss: 0.6621 - acc: 0.5036 - val_loss: 0.6633 - val_acc: 0.2439\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 182us/step - loss: 0.6616 - acc: 0.4728 - val_loss: 0.6633 - val_acc: 0.3063\n",
      "\n",
      "Accuracy: 30.63%\n",
      "\n",
      "learning rate: 6.9e-05\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 90\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 124us/step - loss: 0.6653 - acc: 0.4736 - val_loss: 0.6655 - val_acc: 0.4582\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 0s 60us/step - loss: 0.6634 - acc: 0.4882 - val_loss: 0.6649 - val_acc: 0.4624\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 0s 62us/step - loss: 0.6627 - acc: 0.5017 - val_loss: 0.6645 - val_acc: 0.4709\n",
      "\n",
      "Accuracy: 47.09%\n",
      "\n",
      "learning rate: 1.1e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 427\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 299us/step - loss: 0.7223 - acc: 0.5084 - val_loss: 0.6646 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 225us/step - loss: 0.6622 - acc: 0.5099 - val_loss: 0.6634 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 236us/step - loss: 0.6616 - acc: 0.5247 - val_loss: 0.6633 - val_acc: 0.9409\n",
      "\n",
      "Accuracy: 94.09%\n",
      "\n",
      "learning rate: 1.1e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 425\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 2s 384us/step - loss: 0.6676 - acc: 0.5188 - val_loss: 0.6634 - val_acc: 0.9941\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 281us/step - loss: 0.6617 - acc: 0.4359 - val_loss: 0.6633 - val_acc: 0.4878\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 289us/step - loss: 0.6616 - acc: 0.5376 - val_loss: 0.6633 - val_acc: 0.4911\n",
      "\n",
      "Accuracy: 49.11%\n",
      "\n",
      "learning rate: 4.4e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 418\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 275us/step - loss: 0.6697 - acc: 0.4918 - val_loss: 0.6638 - val_acc: 0.6920\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 214us/step - loss: 0.6624 - acc: 0.5323 - val_loss: 0.6636 - val_acc: 0.7418\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 222us/step - loss: 0.6623 - acc: 0.4489 - val_loss: 0.6636 - val_acc: 0.6498\n",
      "\n",
      "Accuracy: 64.98%\n",
      "\n",
      "learning rate: 3.4e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 405\n",
      "activation: relu\n",
      "\n",
      "Train on 4740 samples, validate on 1185 samples\n",
      "Epoch 1/3\n",
      "4740/4740 [==============================] - 1s 163us/step - loss: 0.6793 - acc: 0.4951 - val_loss: 0.6705 - val_acc: 0.7350\n",
      "Epoch 2/3\n",
      "4740/4740 [==============================] - 1s 147us/step - loss: 0.6709 - acc: 0.5325 - val_loss: 0.6699 - val_acc: 0.7831\n",
      "Epoch 3/3\n",
      "4740/4740 [==============================] - 1s 140us/step - loss: 0.6682 - acc: 0.4800 - val_loss: 0.6664 - val_acc: 0.5316\n",
      "\n",
      "Accuracy: 53.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness, dimensions=dimensions, acq_func='EI', n_calls=40, x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0015745669510686966, 5, 430, 'sigmoid']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(search_result.x)\n",
    "space = search_result.space\n",
    "#space.point_to_dict(search_result.x)\n",
    "search_result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'func_vals', 'models', 'random_state', 'space', 'specs', 'x', 'x_iters']\n",
      "Space([Real(low=1e-06, high=0.01, prior='log-uniform', transform='normalize'),\n",
      "       Integer(low=1, high=5),\n",
      "       Integer(low=5, high=512),\n",
      "       Categorical(categories=('relu', 'sigmoid'), prior=None)])\n"
     ]
    }
   ],
   "source": [
    "#sorted(zip(search_result.func_vals, search_result.x_iters))\n",
    "print(dir(search_result))\n",
    "print(search_result.space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'rcParams'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-fa3fb44b60f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_objective_2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m fig = plot_objective_2D(result=search_result,\n\u001b[0;32m      3\u001b[0m                         \u001b[0mdimension_name1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mdimension_name2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'num_dense_layers'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         levels=50)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\skopt\\plots.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m from .transforms import (Bbox, IdentityTransform, Transform, TransformedBbox,\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'rcParams'"
     ]
    }
   ],
   "source": [
    "from skopt.plots import plot_objective_2D\n",
    "fig = plot_objective_2D(result=search_result,\n",
    "                        dimension_name1='learning_rate',\n",
    "                        dimension_name2='num_dense_layers',\n",
    "                        levels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'output_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-f5512301688d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model = loadModel(path_best_model_h5, path_best_model_json)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    260\u001b[0m           \u001b[0mweighted_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m           \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m           sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[1;31m# Set optimizer weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;31m# Prepare sample weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     self._set_sample_weight_attributes(sample_weight_mode,\n\u001b[1;32m--> 600\u001b[1;33m                                        skip_target_weighing_indices)\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[1;31m# Save all metric attributes per output of the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache_output_metric_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweighted_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\myAzureEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_sample_weight_attributes\u001b[1;34m(self, sample_weight_mode, skip_target_weighing_indices)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;34m\"\"\"Sets sample weight related attributes on the model.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     sample_weights, sample_weight_modes = training_utils.prepare_sample_weights(\n\u001b[1;32m--> 134\u001b[1;33m         self.output_names, sample_weight_mode, skip_target_weighing_indices)\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_weight_modes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight_modes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'output_names'"
     ]
    }
   ],
   "source": [
    "#model = loadModel(path_best_model_h5, path_best_model_json)\n",
    "tf.keras.models.load_model(modelpath, custom_objects=None, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
