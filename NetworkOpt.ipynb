{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Scikit-optimizer\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "#from skopt.plots import plot_convergence\n",
    "#from skopt.plots import plot_objective, plot_evaluations\n",
    "#from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyPart(data):\n",
    "    Xdata = data.iloc[:,0:177]\n",
    "    Ydata = []\n",
    "    for elem in data.iloc[:,177]:\n",
    "        if elem == \"Low\":\n",
    "            Ydata.append(0)\n",
    "        elif elem == \"High\":\n",
    "            Ydata.append(1)\n",
    "    Ydata = np.array(Ydata)\n",
    "    return Xdata, Ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name))\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rdk.fr_C_O_noCOO', 'rdk.Chi4v', 'rdk.fr_Ar_COO', 'rdk.fr_SH',\n",
      "       'rdk.Chi4n', 'rdk.SMR_VSA10', 'rdk.fr_para_hydroxylation',\n",
      "       'rdk.fr_barbitur', 'rdk.fr_halogen', 'rdk.fr_dihydropyridine',\n",
      "       ...\n",
      "       'rdk.PEOE_VSA9', 'rdk.fr_aldehyde', 'rdk.fr_pyridine',\n",
      "       'rdk.fr_tetrazole', 'rdk.RingCount', 'rdk.fr_nitro_arom_nonortho',\n",
      "       'rdk.Chi0v', 'rdk.fr_ArN', 'rdk.NumRotatableBonds', 'c#ClappClass'],\n",
      "      dtype='object', length=178)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('HLMdesc.txt', sep=\"\\t\")\n",
    "data = data.drop(columns = ['Protocol Number', 'Experiment Start Time', 'Experiment Stop Time', 'Result Type Name', 'Result Operator', 'Result Number Rounded',\\\n",
    " 'Project NumName', 'Smiles', 'Leonumber', 'DResult Text', 'DResult Text_1'])\n",
    "data = data.drop(columns = ['Protocol Number_1', 'Experiment Start Time_1', 'Experiment Stop Time_1', 'Result Type Name_1', 'Result Operator_1', 'Result Number Rounded_1', 'Project NumName_1',\\\n",
    "       'Leonumber_1', 'origSmiles_1', 'ClappClass_1'])\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rdk.fr_C_O_noCOO', 'rdk.Chi4v', 'rdk.fr_Ar_COO', 'rdk.fr_SH',\n",
      "       'rdk.Chi4n', 'rdk.SMR_VSA10', 'rdk.fr_para_hydroxylation',\n",
      "       'rdk.fr_barbitur', 'rdk.fr_halogen', 'rdk.fr_dihydropyridine',\n",
      "       ...\n",
      "       'rdk.MolMR', 'rdk.PEOE_VSA9', 'rdk.fr_aldehyde', 'rdk.fr_pyridine',\n",
      "       'rdk.fr_tetrazole', 'rdk.RingCount', 'rdk.fr_nitro_arom_nonortho',\n",
      "       'rdk.Chi0v', 'rdk.fr_ArN', 'rdk.NumRotatableBonds'],\n",
      "      dtype='object', length=177)\n"
     ]
    }
   ],
   "source": [
    "# Seperate test set\n",
    "train = data.sample(frac=0.8,random_state=0)\n",
    "test = data.drop(train.index)\n",
    "#print(len(train))\n",
    "#print(len(test))\n",
    "Xtrain, Ytrain = xyPart(train)\n",
    "Xtest, Ytest = xyPart(test)\n",
    "print(Xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "data_stats = Xtrain.describe()\n",
    "data_stats = data_stats.transpose()\n",
    "def norm(x):\n",
    "  return (x - data_stats['mean']) / data_stats['std']\n",
    "nXtrain = norm(Xtrain)\n",
    "nXtest = norm(Xtest)\n",
    "#print(Xtrain.values[0])\n",
    "#print(nXtrain.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rm columns containing NA\n",
    "allCol = nXtrain.columns\n",
    "ncXtrain = nXtrain.dropna(axis='columns')\n",
    "col = ncXtrain.columns  # After removing NA cols\n",
    "delCol = []\n",
    "for c in allCol:\n",
    "    if c not in col:\n",
    "        delCol.append(c)\n",
    "ncXtest = nXtest.drop(delCol, axis=1)\n",
    "#print(nXtrain.values[0])\n",
    "#print(ncXtrain.values[0])\n",
    "#print(ncXtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(0.00927, 3, 393, \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "    \n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10)\n",
    "history = model.fit(ncXtrain.values, Ytrain, epochs=300,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    val_loss   val_acc      loss       acc  epoch\n",
      "0   0.663318  0.309705  0.785709  0.482278      0\n",
      "1   0.663316  0.200844  0.661562  0.450633      1\n",
      "2   0.663316  0.277637  0.661561  0.419198      2\n",
      "3   0.663316  0.549367  0.661561  0.426793      3\n",
      "4   0.663316  0.717300  0.661561  0.454852      4\n",
      "5   0.663316  0.493671  0.661561  0.495148      5\n",
      "6   0.663316  0.211814  0.661561  0.457384      6\n",
      "7   0.663316  0.215190  0.661561  0.481013      7\n",
      "8   0.663316  0.999156  0.661561  0.455907      8\n",
      "9   0.663316  0.000000  0.661561  0.465401      9\n",
      "10  0.663316  1.000000  0.661561  0.474051     10\n",
      "11  0.663319  1.000000  0.661561  0.495992     11\n",
      "12  0.663316  1.000000  0.661561  0.478692     12\n",
      "13  0.663435  0.000000  0.661567  0.464557     13\n",
      "14  0.663316  0.603376  0.663854  0.493882     14\n",
      "15  0.663316  0.009283  0.661561  0.527848     15\n",
      "16  0.663316  0.786498  0.661561  0.515401     16\n",
      "17  0.663316  0.007595  0.661561  0.524051     17\n",
      "18  0.663316  0.000000  0.661561  0.518776     18\n",
      "19  0.663316  0.850633  0.661561  0.514768     19\n",
      "20  0.663316  0.106329  0.661561  0.496624     20\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Acc')\n",
    "  plt.plot(hist['epoch'], hist['acc'],\n",
    "           label='Train Acc')\n",
    "  plt.plot(hist['epoch'], hist['val_acc'],\n",
    "           label = 'Val Acc')\n",
    "  plt.legend()\n",
    "  plt.ylim([0.5,1])\n",
    "  \n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "print(hist)\n",
    "#plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
